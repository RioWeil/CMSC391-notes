\section{Computational Complexity Theory II}
Remark: \textbf{NP} does not mean non-polynomial, it just means polynomial with respect to a new resource (i.e. already having the solution).

Also, \textbf{NP}-complete means both in \textbf{NP} and is being \textbf{NP}-hard (it is possible for a problem to be \textbf{NP}-hard, but not in \textbf{NP}, i.e. its harder)

\subsection{Randomized Computation}
\textbf{P} is a completely deterministic class. But what if we give the algorithm the power to toss random coins, i.e. the output of the algorithm can depend on the input + a random sequence of coin tosses? Then we arrive at \textbf{BPP} (bounded-error, probabilistic, polynomial time), the class of decision problems that can be decided in poly($n$) time with bounded probability over random coin tosses.

What do we mean about probability? There are two directions:
\begin{itemize}
    \item Completeness probability: If the answer is ``yes'', what is the probability we say yes?
    \item Soundness probability: If the answer is ``no'', what is the probability we say yes?
\end{itemize}
Bounded probability means that the errors we make in both cases are bounded away from a half. I.e. completeness probability is greater than 2/3 (the actual number is not so important, as long as its a constant away from no) and the soundness probability is less than or equal than 1/3 (i.e. teh probability that we accept ``no''s as a yes).

Why do we want these bounded away from 1/2? Then we can amplify the success probabilities by repeating the algorithm + taking a majority vote. If the gap (the difference between the completeness and soundness probabilities) is tiny, then this amplification strategy fails, but if the gap is large then this is a successful strategy.

It's clear that $\textbf{P} \subseteq \textbf{BPP}$. After more than 3 decades of research, we strongly believe that the other inclusion $\textbf{BPP} \subseteq \textbf{P}$ is also true, but an unconditional proof remains elusive.

\subsection{Quantum Computation}
Finally to \textbf{BQP} (bounded error, quantum, polynomial). This is the dream/ideal quantum computation. Let us formalize this precisely so we can talk about the computational power of this class.

\begin{defbox}{: \textbf{BQP} (Informal)}
    The class of decision problems that can be solved with high probability by applying a quantum circuit with poly($n$) gates, measuring the first qubit, and accepting iff the outcome is 1.
\end{defbox}

To formalize this, let's note that if we apply the circuit $U$ to the initial state, and get $\ket{\psi} = U\ket{x}\ket{0^{q(n)}}$ and measure the first qubit in the standard basis we have:
\begin{itemize}
    \item Pr[Output 1] = $\bra{\psi}\Pi_1 \ket{\psi}$
    \item Where $\Pi_1 = \dyad{1}{1} \otimes \II$ a projector (projector: idempotent, equivalently eigenvalues are 1/0) onto the first qubit. In this case, a 2x2 matrix which kills the $\ket{0}$ eigenspace on the first qubit.
\end{itemize}
I.e. it is the set of decision languages $L \subseteq \set{0, 1}^*$ so that there exists some polynomial size family of quantum circuits $\set{Q_n}$ so that after measuring the first qubit:
\begin{itemize}
    \item Letting $\ket{\psi} = Q_n\ket{x}\ket{0^{q(n)}}$
    \item $x \in L \implies \text{Pr[Output 1]} \geq \frac{2}{3}$
    \item $x \notin L \implies \text{Pr[Output 1]} \leq \frac{1}{3}$
\end{itemize}

Remark: The probability here is \emph{not} coming from some probability distribution over classical coin flips. If it were true that we could reproduce quantum randomness with classical randomness, it turns out the polynomial hierarchy collapses!

Some issues/oddities with \textbf{BQP}:

\begin{itemize}
    \item Noise/Decoherence. A polynomial size circuit results in a fidelity of $\sim 2^{-m} = 2^{-\text{poly}(n)}$ where $m$ is the number of gates.
    \item Locality/connectivity. Computer science locality is $k$-locality (bounded degree of interaction) but experimental locality is geometric/spatial. Note that however this is self-consistent within the definition - we allow for polynomial number of operations, and hence we can always use a polynomial number of swap operations to recover the spatial locality from $k$-locality. This would no longer be true if we enforced the notion of constant depth quantum circuits, for example.
    \item Number of measurement appears to be just 1... but indeed we can use the principle of deferred measurement here. Instead of measuring in the middle of the computation, we can associate one measurement per ancilla (apply a CNOT between a physical qubit and the ancilla), and then defer the measurement.
    \item The polynomial depth is notable here. Different depths gives you different amount of power. Shor for example can be done in log depth, but a classical computer would call the log depth circuit multiple times.
    \item This is an asymptotic class: $n$ here is growing. But for some finite number, it doesn't really make sense to ask whether a single/fixed datapoint of number of gates as a function of $n$ is polynomial or exponential... One of the most common NISQ era mistakes. What does it mean to claim an ``exponential speedup'' for $n=53$ qubits? Doesn't make sense! Such claims can be made only asymptotically/scaling an algorithm.
    \item Gatesets: We have a fixed number of possible gates that we can perform in experiment. Not a problem though, because we have a universal gateset (dense subgroup of $SU(2^n)$). Then, Solovay-Kitaev tells us that we can simulate a different gateset with polylog($1/\e$) overhead. This tells us that in the context of \textbf{BQP} we don't have to worry! With polynomial overhead we are totally able to simulate any other gateset with exponential precision. But pragmatically, note we do care about numbers, and hence a lot of work goes into compilation and optimization.
    \item Decision problems: Many problems that we may want to solve on a quantum computer may not be expressable as a decision problem! (e.g. there exists no known decision problem analog of the sampling problem).
\end{itemize}

Next week, we'll start discussing how \textbf{BQP} fits into the landscape of complexity classes we've introduced.